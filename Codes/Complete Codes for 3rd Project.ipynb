{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99e7fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from Bio import SeqIO \n",
    "import numpy as np \n",
    "import random\n",
    "from sklearn.model_selection import train_test_split \n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ecefa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sequences from: C:/Users/sspat/OneDrive/Desktop/card-data/nucleotide_fasta_protein_homolog_model.fasta\n",
      "Successfully loaded 6052 sequences.\n",
      "First 3 ARG IDs: ['gb|GQ343019.1|+|132-1023|ARO:3002999|CblA-1', 'gb|HQ845196.1|+|0-861|ARO:3001109|SHV-52', 'gb|AF028812.1|+|392-887|ARO:3002867|dfrF']\n",
      "Length of first ARG sequence: 891\n",
      "First 50 bases of first ARG sequence: ATGAAAGCATATTTCATCGCCATACTTACCTTATTCACTTGTATAGCTAC...\n",
      "Approximate Average ARG Length: 963.81 bp\n",
      "Approximate Std Dev ARG Length: 303.91 bp\n"
     ]
    }
   ],
   "source": [
    "#1 Collecting ARG Sequences (Positive Samples)\n",
    "def load_fasta_sequences(filepath):\n",
    "    sequences = []\n",
    "    ids = []\n",
    "    print(f\"Loading sequences from: {filepath}\")\n",
    "    try:\n",
    "        for record in SeqIO.parse(filepath, \"fasta\"):\n",
    "            sequences.append(str(record.seq).upper()) #All sequences in uppercase\n",
    "            ids.append(record.id)\n",
    "        print(f\"Successfully loaded {len(sequences)} sequences.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {filepath}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while parsing {filepath}: {e}\")\n",
    "    return ids, sequences\n",
    "\n",
    "#File path\n",
    "arg_fasta_path = \"C:/Users/sspat/OneDrive/Desktop/card-data/nucleotide_fasta_protein_homolog_model.fasta\"\n",
    "arg_ids, arg_sequences = load_fasta_sequences(arg_fasta_path)\n",
    "\n",
    "if not arg_sequences:\n",
    "    print(\"No ARG sequences loaded.\")\n",
    "    avg_arg_len = 1000\n",
    "    std_arg_len = 500\n",
    "else:\n",
    "    print(f\"First 3 ARG IDs: {arg_ids[:3]}\")\n",
    "    print(f\"Length of first ARG sequence: {len(arg_sequences[0])}\")\n",
    "    print(f\"First 50 bases of first ARG sequence: {arg_sequences[0][:50]}...\")\n",
    "    arg_lengths = [len(s) for s in arg_sequences]\n",
    "    avg_arg_len = np.mean(arg_lengths)\n",
    "    std_arg_len = np.std(arg_lengths)\n",
    "    print(f\"Approximate Average ARG Length: {avg_arg_len:.2f} bp\")\n",
    "    print(f\"Approximate Std Dev ARG Length: {std_arg_len:.2f} bp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d12620cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 6052 non-ARG fragments.\n",
      "First 10 generated non-ARGs (lengths): [1316, 865, 1021, 223, 1190, 557, 398, 951, 735, 1014]\n"
     ]
    }
   ],
   "source": [
    "#2 Preparing Non ARG\n",
    "def generate_non_arg_fragments(genome_root_dir, num_target_fragments, avg_len, std_len):\n",
    "    all_genomic_dna = []\n",
    "    \n",
    "    # Collect all genomic sequences\n",
    "    for fna_file in Path(genome_root_dir).rglob('*_genomic.fna'):\n",
    "        try:\n",
    "            for record in SeqIO.parse(fna_file, \"fasta\"):\n",
    "                all_genomic_dna.append(str(record.seq).upper())\n",
    "        except:\n",
    "            pass \n",
    "\n",
    "    if not all_genomic_dna: return [] # Return empty if no DNA loaded\n",
    "\n",
    "    non_arg_fragments = []\n",
    "    max_overall_len = max(len(s) for s in all_genomic_dna) if all_genomic_dna else 3000\n",
    "\n",
    "    # Generate fragments\n",
    "    while len(non_arg_fragments) < num_target_fragments:\n",
    "        selected_seq = random.choice(all_genomic_dna)\n",
    "        \n",
    "        # Sample length and clamp\n",
    "        frag_len = max(100, min(int(np.random.normal(loc=avg_len, scale=std_len)), 3000, len(selected_seq)))\n",
    "\n",
    "        if len(selected_seq) < frag_len: continue # Skip if sequence too short\n",
    "        start_pos = random.randint(0, len(selected_seq) - frag_len)\n",
    "        fragment = selected_seq[start_pos : start_pos + frag_len]\n",
    "        \n",
    "        # Simple N filter\n",
    "        if 'N' not in fragment or fragment.count('N') / len(fragment) <= 0.05:\n",
    "            non_arg_fragments.append(fragment)\n",
    "\n",
    "    print(f\"Generated {len(non_arg_fragments)} non-ARG fragments.\")\n",
    "    return non_arg_fragments\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    avg_arg_len = 963.81 \n",
    "    std_arg_len = 303.91\n",
    "    num_arg_sequences = 6052 \n",
    "    \n",
    "    #Path to Non ARG sequences folder\n",
    "    genomic_data_root = \"C:/Users/sspat/OneDrive/Desktop/Data combined/Data_combined/\" \n",
    "    \n",
    "    non_arg_sequences = generate_non_arg_fragments(\n",
    "        genome_root_dir=genomic_data_root,\n",
    "        num_target_fragments=num_arg_sequences,\n",
    "        avg_len=avg_arg_len,\n",
    "        std_len=std_arg_len\n",
    "    )\n",
    "\n",
    "    print(f\"First 10 generated non-ARGs (lengths): {[len(s) for s in non_arg_sequences[:10]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f08323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset splitting complete.\n"
     ]
    }
   ],
   "source": [
    "#3 Data splitting for CNN\n",
    "# Combine sequences and labels\n",
    "all_sequences = arg_sequences + non_arg_sequences\n",
    "all_labels = [1] * len(arg_sequences) + [0] * len(non_arg_sequences)\n",
    "\n",
    "# Fixed MAX_SEQUENCE_LENGTH\n",
    "MAX_SEQUENCE_LENGTH = 2000 \n",
    "\n",
    "#3-way split: 70% Train, 15% Validation, 15% Test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    all_sequences, all_labels, test_size=0.15, random_state=42, stratify=all_labels\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=(0.15 / (1 - 0.15)), random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"\\nDataset splitting complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd2ac6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding sequences to a fixed length of 2000 bp\n",
      "Shape of X_train_encoded: (8472, 2000, 4)\n",
      "Shape of X_val_encoded: (1816, 2000, 4)\n",
      "Shape of X_test_encoded: (1816, 2000, 4)\n",
      "Shape of y_train_np: (8472,)\n"
     ]
    }
   ],
   "source": [
    "#4 Encoding\n",
    "# Create a mapping from nucleotide characters to their one-hot vectors\n",
    "DNA_TO_ONEHOT = {\n",
    "    'A': [1, 0, 0, 0],\n",
    "    'T': [0, 1, 0, 0],\n",
    "    'C': [0, 0, 1, 0],\n",
    "    'G': [0, 0, 0, 1],\n",
    "    'N': [0, 0, 0, 0]\n",
    "}\n",
    "\n",
    "def one_hot_encode_sequence(sequence, max_len, dna_to_onehot_map):\n",
    "    # Initialize an array of zeros with the target shape (max_len, 4 for ATCG)\n",
    "    encoded_seq = np.zeros((max_len, len(dna_to_onehot_map['A'])), dtype=np.int8)\n",
    "    \n",
    "    # Iterate up to max_len or the actual sequence length, whichever is smaller\n",
    "    for i, char in enumerate(sequence[:max_len]):\n",
    "        if char in dna_to_onehot_map:\n",
    "            encoded_seq[i] = dna_to_onehot_map[char]\n",
    "        else:\n",
    "            # Handle unexpected characters by treating them as 'N' (all zeros)\n",
    "            encoded_seq[i] = dna_to_onehot_map['N']\n",
    "            \n",
    "    return encoded_seq\n",
    "\n",
    "# Apply one-hot encoding\n",
    "print(f\"Encoding sequences to a fixed length of {MAX_SEQUENCE_LENGTH} bp\")\n",
    "X_train_encoded = np.array([one_hot_encode_sequence(s, MAX_SEQUENCE_LENGTH, DNA_TO_ONEHOT) for s in X_train])\n",
    "X_val_encoded = np.array([one_hot_encode_sequence(s, MAX_SEQUENCE_LENGTH, DNA_TO_ONEHOT) for s in X_val])\n",
    "X_test_encoded = np.array([one_hot_encode_sequence(s, MAX_SEQUENCE_LENGTH, DNA_TO_ONEHOT) for s in X_test])\n",
    "\n",
    "# Convert labels to NumPy arrays\n",
    "y_train_np = np.array(y_train)\n",
    "y_val_np = np.array(y_val)\n",
    "y_test_np = np.array(y_test)\n",
    "\n",
    "print(f\"Shape of X_train_encoded: {X_train_encoded.shape}\")\n",
    "print(f\"Shape of X_val_encoded: {X_val_encoded.shape}\")\n",
    "print(f\"Shape of X_test_encoded: {X_test_encoded.shape}\")\n",
    "print(f\"Shape of y_train_np: {y_train_np.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85dc38b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sspat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b5b1f8c8c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 CNN\n",
    "# Model Definition\n",
    "model = Sequential([\n",
    "    Conv1D(128, 8, activation='relu', input_shape=(MAX_SEQUENCE_LENGTH, 4)),\n",
    "    MaxPooling1D(2),\n",
    "    Conv1D(64, 8, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Model Compilation\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(\n",
    "    X_train_encoded, y_train_np,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_encoded, y_val_np),\n",
    "    verbose=0 # Sets verbose to 0 to hide training progress per epoch\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce5baac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Part 4: Model Evaluation\n",
      "Test Loss: 0.1192\n",
      "Test Accuracy: 0.9829\n",
      "Model Evaluation Complete.\n"
     ]
    }
   ],
   "source": [
    "#6  Model Evaluation\n",
    "print(f\"\\nPart 4: Model Evaluation\")\n",
    "\n",
    "# verbose=0 means no detailed output during evaluation, just the final metrics\n",
    "loss, accuracy = model.evaluate(X_test_encoded, y_test_np, verbose=0)\n",
    "#Output\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(\"Model Evaluation Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea4a830e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving\n",
      "Model saved successfully to: C:/Users/sspat/OneDrive/Desktop/ARG Predictor.h5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\n",
      "\n",
      "Predictions on new data:\n",
      "Seq 1 (truncated): ACACGGKTTCGGTCCTCCAGTGCGCTTTCCCGCACCTTCAACCTGGACAT...\n",
      "  Predicted Probability: 0.0000\n",
      "  Predicted Class: 0 (Non-ARG)\n",
      "  True Class: 0 (Non-ARG)\n",
      "\n",
      "Seq 2 (truncated): ATGTCCGCCACGCTCCACGACACCGCAGCGGATCGTCGGAAGGCCACCCG...\n",
      "  Predicted Probability: 1.0000\n",
      "  Predicted Class: 1 (ARG)\n",
      "  True Class: 1 (ARG)\n",
      "\n",
      "Seq 3 (truncated): ATGGCTGCAAGAGCGAAAAATGGCGTAATCGGTTGCGGTCCTAACATTCC...\n",
      "  Predicted Probability: 1.0000\n",
      "  Predicted Class: 1 (ARG)\n",
      "  True Class: 1 (ARG)\n",
      "\n",
      "Seq 4 (truncated): ATGATGAAAAAATCGATATGCTGCGCGCTGCTGCTGACAGCCTCTTTCTC...\n",
      "  Predicted Probability: 1.0000\n",
      "  Predicted Class: 1 (ARG)\n",
      "  True Class: 1 (ARG)\n",
      "\n",
      "Seq 5 (truncated): CTCGACGCCCCGGCCGCTCGACGGCGTGCCGCCGTTCGTCTGGCACGGCT...\n",
      "  Predicted Probability: 0.0000\n",
      "  Predicted Class: 0 (Non-ARG)\n",
      "  True Class: 0 (Non-ARG)\n",
      "\n",
      "Prediction complete.\n"
     ]
    }
   ],
   "source": [
    "#7 Saving the model\n",
    "print(\"\\nSaving\")\n",
    "model_save_path = \"C:/Users/sspat/OneDrive/Desktop/ARG Predictor.h5\"\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved successfully to: {model_save_path}\")\n",
    "\n",
    "#The New DNA sequences must be entered in the variables\n",
    "new_dna_sequences = X_test[:5]\n",
    "true_labels = y_test[:5]\n",
    "\n",
    "#Encoding of the new sequence must be identical to the training of the model: A=[1,0,0,0], T=[0,1,0,0], C=[0,0,1,0], G=[0,0,0,1], N=[0,0,0,0]\n",
    "new_dna_encoded = np.array([\n",
    "    one_hot_encode_sequence(s, MAX_SEQUENCE_LENGTH, DNA_TO_ONEHOT) \n",
    "    for s in new_dna_sequences\n",
    "])\n",
    "\n",
    "#Predictions\n",
    "predictions = model.predict(new_dna_encoded)\n",
    "\n",
    "# Converts probabilities to binary classes (0 or 1)\n",
    "# A common threshold is 0.5: if probability > 0.5, predict 1 (ARG), else 0 (Non-ARG)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "print(f\"\\nPredictions on new data:\")\n",
    "for i, (seq, prob, pred_class, true_class) in enumerate(zip(new_dna_sequences, predictions, predicted_classes, true_labels)):\n",
    "    print(f\"Seq {i+1} (truncated): {seq[:50]}...\")\n",
    "    print(f\"  Predicted Probability: {prob[0]:.4f}\")\n",
    "    print(f\"  Predicted Class: {pred_class[0]} {'(ARG)' if pred_class[0] == 1 else '(Non-ARG)'}\")\n",
    "    print(f\"  True Class: {true_class} {'(ARG)' if true_class == 1 else '(Non-ARG)'}\\n\")\n",
    "\n",
    "print(\"Prediction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afebefe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
